{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = \"1133003\"\n",
    "db_string = f\"postgresql://postgres:{password}@127.0.0.1:5432/voice\"\n",
    "engine = create_engine(db_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.1, valid_size=0.1):\n",
    "    # split training set and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=7)\n",
    "    # split training set and validation set\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size, random_state=7)\n",
    "    # return a dictionary of values\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"y_test\": y_test\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vector_length=128):\n",
    "    \"\"\"5 hidden dense layers from 256 units to 64, not the best model, but not bad.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(vector_length,)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    # one output neuron with sigmoid activation function, 0 means female, 1 means male\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # using binary crossentropy as it's male/female classification (binary)\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "    # print summary of the model\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(category):\n",
    "\n",
    "    if not os.path.isdir(\"results\"):\n",
    "        os.mkdir(\"results\")\n",
    "\n",
    "    # if features & labels already loaded individually and bundled, load them from there instead\n",
    "    if os.path.isfile(\"results/features.npy\") and os.path.isfile(\"results/labels.npy\"):\n",
    "        X = np.load(\"results/features.npy\")\n",
    "        y = np.load(\"results/labels.npy\")\n",
    "        return X, y\n",
    "\n",
    "    x = engine.execute(\n",
    "        \"\"\"\n",
    "        SELECT np_array_bytes, gender\n",
    "        FROM numpy_arrays\n",
    "        WHERE category=%s\n",
    "        \"\"\",\n",
    "        (category)\n",
    "    )\n",
    "\n",
    "    data_list = list(x)\n",
    "    n_samples = len(data_list)\n",
    "    X = np.zeros((n_samples, 128))\n",
    "    # initialize an empty array for all audio labels (1 for male and 0 for female)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    m_count = 0\n",
    "    f_count = 0\n",
    "    for i, (data, gender) in tqdm(enumerate(data_list), \"Loading data\", total = n_samples):\n",
    "        if gender == 1:\n",
    "            m_count += 1\n",
    "        if gender == 0:\n",
    "            f_count += 1\n",
    "        X[i] = pickle.loads(data)\n",
    "        y[i] = gender\n",
    "    np.save(\"results/features\", X)\n",
    "    np.save(\"results/labels\", y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "# for i in x:\n",
    "#     count += 1\n",
    "#     some_array = pickle.loads(i[0])\n",
    "#     print(some_array)\n",
    "#     if count == 2:\n",
    "#         break\n",
    "#     i[1]\n",
    "\n",
    "# some_array = np.random.rand(1500,550)\n",
    "# x.fetchone()[0]\n",
    "# some_array = pickle.loads(x.fetchone()[0])\n",
    "# # some_array = pickle.loads(engine.select()[0])\n",
    "\n",
    "# some_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,545\n",
      "Trainable params: 156,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "928/928 [==============================] - 3s 2ms/step - loss: 0.4758 - accuracy: 0.7948 - val_loss: 0.3202 - val_accuracy: 0.8728\n",
      "Epoch 2/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.3498 - accuracy: 0.8555 - val_loss: 0.2767 - val_accuracy: 0.8878\n",
      "Epoch 3/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.3209 - accuracy: 0.8723 - val_loss: 0.2742 - val_accuracy: 0.8984\n",
      "Epoch 4/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.3033 - accuracy: 0.8820 - val_loss: 0.2549 - val_accuracy: 0.9028\n",
      "Epoch 5/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2951 - accuracy: 0.8875 - val_loss: 0.2488 - val_accuracy: 0.9017\n",
      "Epoch 6/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2830 - accuracy: 0.8902 - val_loss: 0.2386 - val_accuracy: 0.9098\n",
      "Epoch 7/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2784 - accuracy: 0.8936 - val_loss: 0.2276 - val_accuracy: 0.9086\n",
      "Epoch 8/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2749 - accuracy: 0.8948 - val_loss: 0.2250 - val_accuracy: 0.9139\n",
      "Epoch 9/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2682 - accuracy: 0.8980 - val_loss: 0.2350 - val_accuracy: 0.9119\n",
      "Epoch 10/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2660 - accuracy: 0.8990 - val_loss: 0.2308 - val_accuracy: 0.9140\n",
      "Epoch 11/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2606 - accuracy: 0.9028 - val_loss: 0.2149 - val_accuracy: 0.9174\n",
      "Epoch 12/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2573 - accuracy: 0.9022 - val_loss: 0.2191 - val_accuracy: 0.9161\n",
      "Epoch 13/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2549 - accuracy: 0.9041 - val_loss: 0.2138 - val_accuracy: 0.9202\n",
      "Epoch 14/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2535 - accuracy: 0.9050 - val_loss: 0.2214 - val_accuracy: 0.9202\n",
      "Epoch 15/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2523 - accuracy: 0.9058 - val_loss: 0.2133 - val_accuracy: 0.9202\n",
      "Epoch 16/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2503 - accuracy: 0.9073 - val_loss: 0.2134 - val_accuracy: 0.9215\n",
      "Epoch 17/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2485 - accuracy: 0.9084 - val_loss: 0.2100 - val_accuracy: 0.9215\n",
      "Epoch 18/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2430 - accuracy: 0.9093 - val_loss: 0.2075 - val_accuracy: 0.9172\n",
      "Epoch 19/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2453 - accuracy: 0.9092 - val_loss: 0.2082 - val_accuracy: 0.9233\n",
      "Epoch 20/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2430 - accuracy: 0.9095 - val_loss: 0.2072 - val_accuracy: 0.9222\n",
      "Epoch 21/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2412 - accuracy: 0.9094 - val_loss: 0.2061 - val_accuracy: 0.9233\n",
      "Epoch 22/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2372 - accuracy: 0.9094 - val_loss: 0.2009 - val_accuracy: 0.9224\n",
      "Epoch 23/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2380 - accuracy: 0.9116 - val_loss: 0.2024 - val_accuracy: 0.9262\n",
      "Epoch 24/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2339 - accuracy: 0.9148 - val_loss: 0.1961 - val_accuracy: 0.9236\n",
      "Epoch 25/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2346 - accuracy: 0.9135 - val_loss: 0.2072 - val_accuracy: 0.9218\n",
      "Epoch 26/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2338 - accuracy: 0.9128 - val_loss: 0.1974 - val_accuracy: 0.9265\n",
      "Epoch 27/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2290 - accuracy: 0.9144 - val_loss: 0.1937 - val_accuracy: 0.9265\n",
      "Epoch 28/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2294 - accuracy: 0.9142 - val_loss: 0.1914 - val_accuracy: 0.9249\n",
      "Epoch 29/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2303 - accuracy: 0.9145 - val_loss: 0.1903 - val_accuracy: 0.9255\n",
      "Epoch 30/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2253 - accuracy: 0.9158 - val_loss: 0.1936 - val_accuracy: 0.9240\n",
      "Epoch 31/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2249 - accuracy: 0.9167 - val_loss: 0.1960 - val_accuracy: 0.9268\n",
      "Epoch 32/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2284 - accuracy: 0.9162 - val_loss: 0.1903 - val_accuracy: 0.9230\n",
      "Epoch 33/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2266 - accuracy: 0.9169 - val_loss: 0.1991 - val_accuracy: 0.9208\n",
      "Epoch 34/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2242 - accuracy: 0.9180 - val_loss: 0.1979 - val_accuracy: 0.9233\n",
      "Epoch 35/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2229 - accuracy: 0.9177 - val_loss: 0.1894 - val_accuracy: 0.9268\n",
      "Epoch 36/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2219 - accuracy: 0.9180 - val_loss: 0.1924 - val_accuracy: 0.9292\n",
      "Epoch 37/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2224 - accuracy: 0.9181 - val_loss: 0.1949 - val_accuracy: 0.9242\n",
      "Epoch 38/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2247 - accuracy: 0.9184 - val_loss: 0.1924 - val_accuracy: 0.9272\n",
      "Epoch 39/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2228 - accuracy: 0.9184 - val_loss: 0.2016 - val_accuracy: 0.9269\n",
      "Epoch 40/100\n",
      "928/928 [==============================] - 2s 2ms/step - loss: 0.2210 - accuracy: 0.9191 - val_loss: 0.1915 - val_accuracy: 0.9280\n",
      "Evaluating the model using 7328 samples...\n",
      "Loss: 0.1918\n",
      "Accuracy: 92.75%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "# load the dataset\n",
    "X, y = load_data(\"cv-valid-train\")\n",
    "# split the data into training, validation and testing sets\n",
    "data = split_data(X, y, test_size=0.1, valid_size=0.1)\n",
    "# construct the model\n",
    "model = create_model()\n",
    "\n",
    "# use tensorboard to view metrics\n",
    "tensorboard = TensorBoard(log_dir=\"logs\")\n",
    "# define early stopping to stop training after 5 epochs of not improving\n",
    "early_stopping = EarlyStopping(mode=\"min\", patience=5, restore_best_weights=True)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "\n",
    "# train the model using the training set and validating using validation set\n",
    "model.fit(data[\"X_train\"], data[\"y_train\"], epochs=epochs, batch_size=batch_size, validation_data=(data[\"X_valid\"], data[\"y_valid\"]),\n",
    "          callbacks=[tensorboard, early_stopping])\n",
    "\n",
    "# save the model to a file\n",
    "model.save(\"results/model.h5\")\n",
    "\n",
    "# evaluating the model using the testing set\n",
    "print(f\"Evaluating the model using {len(data['X_test'])} samples...\")\n",
    "loss, accuracy = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
